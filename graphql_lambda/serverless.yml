# Welcome to Serverless!
#
# This file is the main config file for your service.
# It's very minimal at this point and uses default values.
# You can always add more config options for more control.
# We've included some commented out config examples here.
# Just uncomment any of them to get that config option.
#
# For full config options, check the docs:
#    docs.serverless.com
#
# Happy Coding!

service: graphql-lambda
# app and org for use with dashboard.serverless.com
#app: your-app-name
#org: your-org-name

# You can pin your service to only deploy with a specific Serverless version
# Check out our docs for more details
# frameworkVersion: "=X.X.X"

provider:
  name: aws
  runtime: nodejs10.x
  memorySize: 192
  environment:
    DYNAMODB_TABLE_AGGREGATES: ${self:service}-${self:provider.stage}-aggregates
    DYNAMODB_TABLE_EVENTS: ${self:service}-${self:provider.stage}-events
    DYNAMODB_TABLE_CLASSCONNECT: ${self:service}-${self:provider.stage}-classconnect
    NEW_EVENTS_QUEUE: !Ref NewEventsQueue
  # iamManagedPolicies:
  #   - AWSLambdaBasicExecutionRole
  iamRoleStatements:
    - Effect: Allow
      Action:
        - dynamodb:GetItem
        - dynamodb:PutItem
        - dynamodb:UpdateItem
        - dynamodb:DeleteItem
      Resource: "arn:aws:dynamodb:${opt:region, self:provider.region}:*:table/${self:provider.environment.DYNAMODB_TABLE_AGGREGATES}"
    - Effect: Allow
      Action:
        - dynamodb:GetItem
        - dynamodb:PutItem
        - dynamodb:UpdateItem
        - dynamodb:DeleteItem
        - dynamodb:Query
      Resource: "arn:aws:dynamodb:${opt:region, self:provider.region}:*:table/${self:provider.environment.DYNAMODB_TABLE_EVENTS}"
    - Effect: Allow
      Action:
        - dynamodb:GetItem
        - dynamodb:PutItem
        - dynamodb:UpdateItem
        - dynamodb:DeleteItem
        - dynamodb:Query
      Resource: "arn:aws:dynamodb:${opt:region, self:provider.region}:*:table/${self:provider.environment.DYNAMODB_TABLE_CLASSCONNECT}"

    # SQS Same Account
    # Required by dynamo stream handler
    - Effect: Allow
      Action:
        - sqs:*
      Resource:
        # Sub style prevents circular reference
        #- !Sub arn:aws:sqs:${opt:region, self:provider.region}:${AWS::AccountId}:*
        # - arn:aws:sqs:us-east-1:205970018521:graphql-lambda-dev-NewEventsQueue-4RS8GUHUNC8Q.fifo
        - !GetAtt NewEventsQueue.Arn

resources:
  Resources:
    EventAggregatesTable:
      Type: 'AWS::DynamoDB::Table'
      Properties:
        BillingMode: PAY_PER_REQUEST
        AttributeDefinitions:
          - AttributeName: aggregate_id
            AttributeType: S
        KeySchema:
          - AttributeName: aggregate_id
            KeyType: HASH
        TableName: ${self:provider.environment.DYNAMODB_TABLE_AGGREGATES}
    EventsTable:
      Type: 'AWS::DynamoDB::Table'
      Properties:
        BillingMode: PAY_PER_REQUEST
        AttributeDefinitions:
          - AttributeName: aggregate_id
            AttributeType: S
          - AttributeName: version
            AttributeType: N
        KeySchema:
          - AttributeName: aggregate_id
            KeyType: HASH
          - AttributeName: version
            KeyType: RANGE
        TableName: ${self:provider.environment.DYNAMODB_TABLE_EVENTS}
        # Emits events for NEW_IMAGE only (because we only insert new items)
        StreamSpecification:
          StreamViewType: NEW_IMAGE

    # For demo purposes, pretend the view layer is a single dynamo DB table
    # In reality it can be a nice relational table, Elasticsearch, Mongo, whatever.
    # It should be optimized for what the read layer needs! That's part of the point.
    ClassConnectTable:
      Type: 'AWS::DynamoDB::Table'
      Properties:
        BillingMode: PAY_PER_REQUEST
        AttributeDefinitions:
          - AttributeName: id
            AttributeType: S
        KeySchema:
          - AttributeName: id
            KeyType: HASH
        TableName: ${self:provider.environment.DYNAMODB_TABLE_CLASSCONNECT}

    NewEventsQueue:
      Type: AWS::SQS::Queue
      # Properties:
      #   # TODO: This probably doesn't NEED to be fifo, but it avoids having to
      #   #       re-queue in case events are out of order for demo only.
      #   ContentBasedDeduplication: true
      #   FifoQueue: true

    QueuePolicy:
      Type: AWS::SQS::QueuePolicy
      Properties:
        Queues:
          - !Ref NewEventsQueue
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
            - Effect: Allow
              Principal:
                # the Fn::Join is a workaround for something something https://forum.serverless.com/t/getting-handle-accountid-in-serverless-config/946/13
                # AWS: !Sub ${AWS::AccountId}
                AWS:
                  Fn::Join: ["", [{ Ref: "AWS::AccountId" }]]
              Action:
                - sqs:SendMessage
              Resource:
                - !GetAtt NewEventsQueue.Arn

plugins:
  - serverless-plugin-typescript
  - serverless-offline

# you can overwrite defaults here
#  stage: dev
#  region: us-east-1

# you can add statements to the Lambda function's IAM Role here
#  iamRoleStatements:
#    - Effect: "Allow"
#      Action:
#        - "s3:ListBucket"
#      Resource: { "Fn::Join" : ["", ["arn:aws:s3:::", { "Ref" : "ServerlessDeploymentBucket" } ] ]  }
#    - Effect: "Allow"
#      Action:
#        - "s3:PutObject"
#      Resource:
#        Fn::Join:
#          - ""
#          - - "arn:aws:s3:::"
#            - "Ref" : "ServerlessDeploymentBucket"
#            - "/*"

# you can define service wide environment variables here
#  environment:
#    variable1: value1

# you can add packaging information here
#package:
#  include:
#    - include-me.js
#    - include-me-dir/**
#  exclude:
#    - exclude-me.js
#    - exclude-me-dir/**
package:
  # exclude:
  #   - node_modules/**/*
  include:
    - handler.ts
    - dynamo-stream-to-sqs.ts

functions:
  graphqlAction:
    handler: handler.writeAPI
    events:
      - http:
          path: graphql/action
          method: post
          cors: true

  graphqlQuery:
    handler: handler.readAPI
    events:
      - http:
          path: graphql/query
          method: post
          cors: true

  dynamoStreamToSQS:
    handler: dynamo-stream-to-sqs.handler
    description: 'Streams Dynamo EventStore Events to SQS FIFO queues'
    events:
      - stream:
          type: dynamodb
          startingPosition: LATEST
          batchSize: 1 # TODO: Lambda Handler only looks at first Record
          enabled: true
          arn: !GetAtt EventsTable.StreamArn

  eventProcessor:
    handler: event-processor/handler.onMessage
    events:
      - sqs:
          arn:
            Fn::GetAtt:
              - NewEventsQueue
              - Arn

#    The following are a few example events you can configure
#    NOTE: Please make sure to change your handler code to work with those events
#    Check the event documentation for details
#    events:
#      - http:
#          path: users/create
#          method: get
#      - websocket: $connect
#      - s3: ${env:BUCKET}
#      - schedule: rate(10 minutes)
#      - sns: greeter-topic
#      - stream: arn:aws:dynamodb:region:XXXXXX:table/foo/stream/1970-01-01T00:00:00.000
#      - alexaSkill: amzn1.ask.skill.xx-xx-xx-xx
#      - alexaSmartHome: amzn1.ask.skill.xx-xx-xx-xx
#      - iot:
#          sql: "SELECT * FROM 'some_topic'"
#      - cloudwatchEvent:
#          event:
#            source:
#              - "aws.ec2"
#            detail-type:
#              - "EC2 Instance State-change Notification"
#            detail:
#              state:
#                - pending
#      - cloudwatchLog: '/aws/lambda/hello'
#      - cognitoUserPool:
#          pool: MyUserPool
#          trigger: PreSignUp
#      - alb:
#          listenerArn: arn:aws:elasticloadbalancing:us-east-1:XXXXXX:listener/app/my-load-balancer/50dc6c495c0c9188/
#          priority: 1
#          conditions:
#            host: example.com
#            path: /hello

#    Define function environment variables here
#    environment:
#      variable2: value2

# you can add CloudFormation resource templates here
#resources:
#  Resources:
#    NewResource:
#      Type: AWS::S3::Bucket
#      Properties:
#        BucketName: my-new-bucket
#  Outputs:
#     NewOutput:
#       Description: "Description for the output"
#       Value: "Some output value"
